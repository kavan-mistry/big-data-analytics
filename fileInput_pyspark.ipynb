{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1YqOYQtpV_vMremp5O2_5vmlu5QHYY7dE","authorship_tag":"ABX9TyN2+psVVbmuZg8vdUG1My1P"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I7QBtWxeQ0k6","executionInfo":{"status":"ok","timestamp":1693026903218,"user_tz":-330,"elapsed":47838,"user":{"displayName":"SAL19IT 6023kavanmistry","userId":"03477421122245380763"}},"outputId":"e9c4b845-ac23-48f0-9ebb-63bb2e399741"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pyspark\n","  Downloading pyspark-3.4.1.tar.gz (310.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.8/310.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n","Building wheels for collected packages: pyspark\n","  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyspark: filename=pyspark-3.4.1-py2.py3-none-any.whl size=311285387 sha256=dd9f05d722644db82cf6d1ba1c87f722d84672776633e91c0cefbb1492c78af9\n","  Stored in directory: /root/.cache/pip/wheels/0d/77/a3/ff2f74cc9ab41f8f594dabf0579c2a7c6de920d584206e0834\n","Successfully built pyspark\n","Installing collected packages: pyspark\n","Successfully installed pyspark-3.4.1\n"]}],"source":["!pip install pyspark"]},{"cell_type":"code","source":["from pyspark.sql import SparkSession"],"metadata":{"id":"nIiN2eRIQ2on","executionInfo":{"status":"ok","timestamp":1693026912932,"user_tz":-330,"elapsed":5,"user":{"displayName":"SAL19IT 6023kavanmistry","userId":"03477421122245380763"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["spark = SparkSession.builder.appName(\"WordCount\").getOrCreate()\n","\n","input_file = \"/content/drive/MyDrive/data_set/my_file_input.txt\"\n","output_dir = \"/content/drive/MyDrive/data_set/my_file_output\"\n","\n","lines = spark.sparkContext.textFile(input_file)\n","words = lines.flatMap(lambda line: line.split())\n","word_counts = words.map(lambda word: (word, 1)).reduceByKey(lambda a, b: a + b)\n","sorted_word_counts = word_counts.sortBy(lambda x: x[1], ascending=False)\n","\n","sorted_word_counts.saveAsTextFile(output_dir)\n","\n","spark.stop()\n"],"metadata":{"id":"BWb5DysrRIYt","executionInfo":{"status":"ok","timestamp":1693027197301,"user_tz":-330,"elapsed":8154,"user":{"displayName":"SAL19IT 6023kavanmistry","userId":"03477421122245380763"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"qKBASYbnRpjm"},"execution_count":null,"outputs":[]}]}